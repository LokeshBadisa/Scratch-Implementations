{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3519529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch Imports\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Distribution Imports\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "# import torch.distributed as dist\n",
    "# import torch.multiprocessing as mp\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# NLP Imports\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Miscellaneous Imports\n",
    "from os.path import exists\n",
    "from math import sqrt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635b61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting device\n",
    "device = t.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d508cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fd043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Generator Style Dataset to Map Style Dataset\n",
    "train = to_map_style_dataset(train)\n",
    "test = to_map_style_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04fe660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see 3rd German-English sentence pair in dataset\n",
    "#train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1343c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dependencies\n",
    "spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed005157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize in source and target language\n",
    "def tokenize(text, tokenizer):\n",
    "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return tokenize(text, spacy_de)\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return tokenize(text, spacy_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb99aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizes from each sentence in dataset \n",
    "def yield_tokens(data_iter, tokenizer, index):\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer(from_to_tuple[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa470f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for seeing sentence pairs in vocabulary\n",
    "# for label, line in train:\n",
    "#     print(label)\n",
    "#     print(line)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7a5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds Vocabulary of source and target language\n",
    "def build_vocabulary(spacy_de, spacy_en):\n",
    "\n",
    "    print(\"Building German Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_de, index=0),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    print(\"Building English Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_en, index=1),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
    "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
    "\n",
    "    return vocab_src, vocab_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427445ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Vocabulary\n",
    "def load_vocab(spacy_de, spacy_en):\n",
    "    if not exists(\"vocab.pt\"):\n",
    "        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)\n",
    "        t.save((vocab_src, vocab_tgt), \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_src, vocab_tgt = t.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(len(vocab_src))\n",
    "    print(len(vocab_tgt))\n",
    "    return vocab_src, vocab_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53fad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n",
      "8315\n",
      "6384\n"
     ]
    }
   ],
   "source": [
    "source_vocab,target_vocab = load_vocab(spacy_de, spacy_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f78d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment for length of target vocabulary\n",
    "#len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35644ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for indices of each word\n",
    "#target_vocab(tokenize_en(\"Two young, White males are outside near many bushes.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a06a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this for vocabulary in target language\n",
    "#target_vocab.lookup_tokens(range(target_vocab.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ef76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence pre-processing Helper Function\n",
    "def collate_batch(\n",
    "    batch,\n",
    "    device,\n",
    "    max_padding=128,\n",
    "    pad_id=2,\n",
    "):\n",
    "    bs_id = t.tensor([0], device=device)  # <s> token id\n",
    "    eos_id = t.tensor([1], device=device)  # </s> token id\n",
    "    src_list, tgt_list = [], []\n",
    "    for (_src, _tgt) in batch:\n",
    "        processed_src = t.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                t.tensor(\n",
    "                    source_vocab(tokenize_de(_src)),\n",
    "                    dtype=t.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ]\n",
    "        )\n",
    "        processed_tgt = t.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                t.tensor(\n",
    "                    target_vocab(tokenize_en(_tgt)),\n",
    "                    dtype=t.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ]\n",
    "        )\n",
    "        src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    max_padding - len(processed_src),\n",
    "                ),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "        tgt_list.append(\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (0, max_padding - len(processed_tgt)),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    src = t.stack(src_list)\n",
    "    tgt = t.stack(tgt_list)\n",
    "    return (src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5edf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate Function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    return collate_batch(\n",
    "    batch,\n",
    "    device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbeab592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = DistributedSampler(train_iter_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c1d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "        train,\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "#         sampler = train_sampler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e633f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   0,    5,   12,  ...,    2,    2,    2],\n",
      "        [   0,    5,   12,  ...,    2,    2,    2],\n",
      "        [   0,   60,  120,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [   0,    5, 2480,  ...,    2,    2,    2],\n",
      "        [   0,    5,  100,  ...,    2,    2,    2],\n",
      "        [   0,    5,   75,  ...,    2,    2,    2]]), tensor([[   0,  111,   21,  ...,    2,    2,    2],\n",
      "        [   0,    6,   12,  ...,    2,    2,    2],\n",
      "        [   0,  223,   17,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [   0, 5038,    7,  ...,    2,    2,    2],\n",
      "        [   0,    6,   25,  ...,    2,    2,    2],\n",
      "        [   0,    6,   77,  ...,    2,    2,    2]]))\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dafe5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t.stack(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc7cd216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "46592a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        y = t.arange(self.d_model/2)        \n",
    "        y = t.repeat_interleave(y,2)\n",
    "        Z = t.empty((128,512))\n",
    "        for _ in range(Z.shape[0]):\n",
    "            Z[_] = y\n",
    "        Z = Z/self.d_model\n",
    "        Z = 1/(1e4)**Z\n",
    "        Z = t.arange(X.shape[1])*Z\n",
    "        Z[:, 0::2] = torch.sin(Z[:, 0::2])\n",
    "        Z[:, 1::2] = torch.cos(Z[:, 1::2])\n",
    "        Z = nn.LayerNorm(Z.shape)(Z+X)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c8ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nHEADS is number of heads in multi-attention\n",
    "# d_model refers to representation size of each word\n",
    "# HIDDEN_SIZE refers to size of query, key and value vectors.\n",
    "nHEADS = 8\n",
    "d_model = 512\n",
    "HIDDEN_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ac271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embeddings\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model,device=device)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.lut(X) * sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b96b4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention in Encoder\n",
    "class EncAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncAttention, self).__init__()\n",
    "        self.Wq = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wk = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wv = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wo = nn.Parameter(t.rand(nHEADS*HIDDEN_SIZE, d_model)).to(device)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        ans = t.empty_like(data)\n",
    "        for i,X in enumerate(data):\n",
    "            X = X.to(device)\n",
    "            Q = X@self.Wq\n",
    "            K = X@self.Wk\n",
    "            V = X@self.Wv\n",
    "            Z = t.bmm(Q,K.transpose(1,2))/sqrt(HIDDEN_SIZE)\n",
    "            Z = nn.Softmax(dim=2)(Z)\n",
    "            Z = t.einsum('ijj->ij',[Z])\n",
    "            Z = t.einsum('ij,ijk->ijk',Z,V)\n",
    "            Z = t.reshape(Z,(Z.shape[1],-1))\n",
    "            Z = Z@self.Wo\n",
    "            Z = nn.Dropout(p=0.1)(Z)\n",
    "            Z = nn.LayerNorm(Z.shape,device=device)(Z+X)\n",
    "            ans[i] = Z\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0e69547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0b764f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_embed = Embeddings(512,len(source_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6fb1d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "deuinput = deu_embed(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "26f9e1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deuinput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c0d3d5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2945e+00,  2.5852e+00,  2.6700e+00,  ..., -6.6141e-02,\n",
       "           2.7845e+00,  1.4183e+00],\n",
       "         [-7.2415e-02, -5.8308e-02, -6.5369e-02,  ..., -6.2374e-02,\n",
       "          -5.8457e-02, -6.5039e-02],\n",
       "         [-2.0307e+00, -2.1051e+00, -2.1845e+00,  ..., -2.0963e+00,\n",
       "          -2.1695e+00, -2.3917e+00],\n",
       "         ...,\n",
       "         [-6.8764e-02, -6.6751e-02, -6.9084e-02,  ..., -6.6754e-02,\n",
       "          -6.0466e-02, -6.5416e-02],\n",
       "         [-6.8764e-02, -6.6751e-02, -6.9084e-02,  ..., -6.6754e-02,\n",
       "          -6.0466e-02, -6.5416e-02],\n",
       "         [-6.8764e-02, -5.5299e-02, -6.9084e-02,  ..., -6.6754e-02,\n",
       "          -6.0466e-02, -6.5416e-02]],\n",
       "\n",
       "        [[ 3.2058e+00,  2.8280e+00,  3.1228e+00,  ...,  3.2207e+00,\n",
       "           3.0587e+00,  3.8805e+00],\n",
       "         [-3.9858e+00, -3.1613e+00, -3.6970e+00,  ...,  2.5524e-01,\n",
       "          -3.4223e+00, -3.9652e+00],\n",
       "         [ 8.7728e-03,  1.7313e-02,  7.3248e-03,  ...,  2.1989e-02,\n",
       "           1.1406e-02,  1.7662e-02],\n",
       "         ...,\n",
       "         [ 1.0039e-02,  1.3509e-02,  9.4874e-03,  ...,  1.9258e-02,\n",
       "           7.8515e-03,  1.5810e-02],\n",
       "         [ 1.0039e-02,  1.3509e-02,  9.4874e-03,  ...,  1.9258e-02,\n",
       "           1.4083e-02,  1.5810e-02],\n",
       "         [ 1.0039e-02,  1.3509e-02,  9.4874e-03,  ...,  1.9258e-02,\n",
       "           1.4083e-02,  1.5810e-02]],\n",
       "\n",
       "        [[ 3.1872e+00,  2.8090e+00,  2.9002e+00,  ...,  2.8863e+00,\n",
       "           2.8013e+00,  3.4176e+00],\n",
       "         [-3.0163e+00, -2.3164e+00, -2.8090e+00,  ..., -2.3736e+00,\n",
       "           8.9931e-01, -3.0199e+00],\n",
       "         [-2.2623e-02, -2.5279e-02, -3.1810e-02,  ..., -1.7227e-02,\n",
       "          -1.5316e-02, -2.4940e-02],\n",
       "         ...,\n",
       "         [-2.7173e-02, -2.2892e-02, -2.7587e-02,  ..., -1.9163e-02,\n",
       "          -2.0823e-02, -2.2843e-02],\n",
       "         [-2.7173e-02, -2.2892e-02, -2.7587e-02,  ..., -1.9163e-02,\n",
       "          -2.0823e-02, -2.2843e-02],\n",
       "         [-2.7173e-02, -2.2892e-02, -2.7587e-02,  ..., -1.9163e-02,\n",
       "          -2.0823e-02, -2.2843e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5670e-02,  3.2721e+00,  5.9712e+00,  ...,  4.8297e+00,\n",
       "           2.4433e+00,  9.8690e+00],\n",
       "         [-1.1667e-01, -8.1114e-02, -3.0387e-02,  ...,  1.3172e-02,\n",
       "          -5.3571e-02, -2.6346e-02],\n",
       "         [-8.6897e-02, -1.1744e-01, -7.1980e-02,  ..., -1.2129e-01,\n",
       "          -9.9300e-02, -7.2453e-02],\n",
       "         ...,\n",
       "         [-7.1967e-02, -4.3882e-02, -7.5885e-02,  ..., -4.7350e-02,\n",
       "          -8.3934e-02, -3.0969e-02],\n",
       "         [-7.1967e-02, -4.7318e-02, -7.5885e-02,  ..., -4.7350e-02,\n",
       "          -8.3934e-02, -3.0969e-02],\n",
       "         [-7.1967e-02, -4.3882e-02, -7.5885e-02,  ..., -4.7350e-02,\n",
       "          -8.3934e-02, -3.0969e-02]],\n",
       "\n",
       "        [[-2.6981e-01, -1.9854e-01, -2.5249e-01,  ..., -2.5275e-01,\n",
       "          -1.9815e-01, -2.5258e-01],\n",
       "         [-2.6858e-01, -2.0811e-01, -2.5080e-01,  ..., -2.2984e-01,\n",
       "          -1.9341e-01, -2.4996e-01],\n",
       "         [ 5.0537e+00,  4.0102e+00, -2.4791e-01,  ...,  3.6692e+00,\n",
       "           4.3347e+00,  1.8544e+00],\n",
       "         ...,\n",
       "         [-2.5937e-01, -1.9984e-01, -2.6017e-01,  ..., -2.3957e-01,\n",
       "          -2.0039e-01, -2.5092e-01],\n",
       "         [-2.5937e-01, -1.9984e-01, -2.6017e-01,  ..., -2.3957e-01,\n",
       "          -2.0039e-01, -2.5092e-01],\n",
       "         [-2.5937e-01, -1.9984e-01, -2.6017e-01,  ..., -2.3957e-01,\n",
       "          -2.0039e-01, -2.5092e-01]],\n",
       "\n",
       "        [[ 3.9646e+00,  3.2509e+00, -1.0847e-01,  ...,  3.5491e+00,\n",
       "           3.4957e+00,  4.6927e+00],\n",
       "         [-1.2687e+00, -1.5535e+00, -1.7458e+00,  ..., -1.9061e+00,\n",
       "          -2.4163e+00, -2.2167e+00],\n",
       "         [-1.1279e-01, -1.0665e-01, -1.1162e-01,  ..., -1.1630e-01,\n",
       "          -8.1946e-02, -1.1315e-01],\n",
       "         ...,\n",
       "         [-1.1487e-01, -8.8571e-02, -1.1562e-01,  ..., -1.0995e-01,\n",
       "          -9.7486e-02, -1.0699e-01],\n",
       "         [-1.1487e-01, -8.8571e-02, -1.1562e-01,  ..., -1.0995e-01,\n",
       "          -9.7486e-02, -1.0699e-01],\n",
       "         [-1.1487e-01, -8.8571e-02, -1.1562e-01,  ..., -1.0995e-01,\n",
       "          -9.7486e-02, -1.0699e-01]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52180b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Zf = model1(deuinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ceb66353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed20190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5d717235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-Forward Network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(512,2048,device=device)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2048,512,device=device)\n",
    "        self.relu2 = nn.ReLU()\n",
    "            \n",
    "    def forward(self,data):\n",
    "        ans = t.empty_like(data)\n",
    "        for i,X in enumerate(data):\n",
    "            Z = self.linear1(X)\n",
    "            Z = self.relu1(Z)\n",
    "            Z = self.linear2(Z)\n",
    "            Z = self.relu2(Z)\n",
    "            Z = nn.Dropout(p=0.1)(Z)\n",
    "            Z = nn.LayerNorm(Z.shape,device=device)(Z+X)\n",
    "            ans[i] = Z\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7069541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = EncAttention()\n",
    "        self.feedforward = FeedForward()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        Z = self.attention(X)\n",
    "        Z = self.feedforward(Z)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c540ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Attention in Decoder\n",
    "class MaskedAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedAttention, self).__init__()\n",
    "        self.Wq = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wk = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wv = nn.Parameter(t.rand(nHEADS, d_model, HIDDEN_SIZE)).to(device)\n",
    "        self.Wo = nn.Parameter(t.rand(nHEADS*HIDDEN_SIZE, d_model)).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self,data):\n",
    "        ans = t.empty_like(data)\n",
    "        rQ = t.empty(data.shape[0],nHEADS,128,HIDDEN_SIZE)\n",
    "        for i,X in enumerate(data):\n",
    "            Q = X@self.Wq\n",
    "            K = X@self.Wk\n",
    "            V = X@self.Wv\n",
    "            Z = t.bmm(Q,K.transpose(1,2))/sqrt(HIDDEN_SIZE)\n",
    "            r,c = t.triu_indices(Z.shape[1],Z.shape[1],1)\n",
    "            Z[:,r,c] = float('-inf')\n",
    "            Z = nn.Softmax(dim=2)(Z)\n",
    "            Z = t.einsum('ijj->ij',[Z])\n",
    "            Z = t.einsum('ij,ijk->ijk',Z,V)\n",
    "            Z = t.reshape(Z,(Z.shape[1],-1))\n",
    "            Z = Z@self.Wo\n",
    "            Z = nn.Dropout(p=0.1)(Z)\n",
    "            Z = nn.LayerNorm(Z.shape,device=device)(Z+X)\n",
    "            ans[i] = Z\n",
    "            rQ[i] = Q\n",
    "        return ans.reshape(ans.shape[0],nHEADS,ans.shape[1],-1), rQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8147df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MaskedAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1d3ac655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_embed = Embeddings(512,len(target_vocab))\n",
    "enginput = eng_embed(data[1])\n",
    "enginput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8fe51e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e225b5060cbd433e896f5422ea471871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Zf2 = model2(enginput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "73ce08b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 8, 128, 64]), torch.Size([100, 8, 128, 64]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf2[0].shape,Zf2[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "20e0f275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "45171499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = EncDecAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c0a6ea0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f4a74607f44c53a5199bab29f80563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Zf3 = model3(Zf2[0],Zf2[1],Zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f99b8144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "232013b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = FeedForward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b422ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170dd828cbca4a70bd2ce13fa5dfbf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Zf4 = model4(Zf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b53c0a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "92854257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cf027e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zf10 = model10(deuinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3f55df0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3430,  0.1841,  0.7273,  ...,  0.3474, -0.6324,  0.3642],\n",
       "         [-0.6915, -0.7025,  0.4740,  ...,  1.2667, -0.3313,  0.8768],\n",
       "         [-0.5146,  0.6635,  0.0222,  ...,  0.0369, -0.5946,  1.2212],\n",
       "         ...,\n",
       "         [ 0.2136,  0.5731, -0.3884,  ...,  0.6604, -0.3898,  0.5286],\n",
       "         [ 0.2136,  0.5731, -0.3884,  ...,  0.6604, -0.3898,  0.5286],\n",
       "         [ 0.2136,  0.5731, -0.3884,  ...,  0.6604, -0.3898,  0.5286]],\n",
       "\n",
       "        [[-1.2767,  0.2291,  0.6541,  ...,  0.4024, -0.6779,  0.3755],\n",
       "         [-0.6438, -0.6876,  0.5122,  ...,  1.2951, -0.3327,  0.7990],\n",
       "         [-0.4932,  0.7473, -0.0041,  ...,  0.0363, -0.6141,  1.2131],\n",
       "         ...,\n",
       "         [ 0.2151,  0.5731, -0.3877,  ...,  0.6585, -0.3884,  0.5291],\n",
       "         [ 0.2151,  0.5731, -0.3877,  ...,  0.6585, -0.6249,  0.5291],\n",
       "         [ 0.2151,  0.5731, -0.3877,  ...,  0.6585, -0.3884,  0.5291]],\n",
       "\n",
       "        [[-1.3429,  0.0608,  0.6564,  ...,  0.3815, -0.7313,  0.3517],\n",
       "         [ 0.5192,  1.0687,  0.9969,  ..., -0.6119,  0.6768, -1.4269],\n",
       "         [ 0.6954,  0.4613, -1.2030,  ...,  0.3254,  1.4800,  0.1914],\n",
       "         ...,\n",
       "         [ 0.2154,  0.5742, -0.3876,  ...,  0.6602, -0.3886,  0.5299],\n",
       "         [ 0.2154,  0.1960, -0.3876,  ...,  0.6602, -0.6251,  0.5300],\n",
       "         [ 0.2154,  0.5742, -0.3876,  ...,  0.6602, -0.3886,  0.5299]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3441,  0.1855,  0.7311,  ...,  0.3495, -0.6321,  0.3663],\n",
       "         [-0.6891, -0.7996,  0.5427,  ...,  1.2933, -0.3429,  0.8786],\n",
       "         [-0.5619, -1.9380, -0.3078,  ..., -1.2943, -1.2989, -0.2753],\n",
       "         ...,\n",
       "         [-0.3075,  0.5750, -0.3877,  ...,  0.6595, -0.3879,  0.5311],\n",
       "         [ 0.2170,  0.5750, -0.3877,  ...,  0.6595, -0.3879,  0.5311],\n",
       "         [ 0.2170,  0.5750, -0.3877,  ...,  0.6595, -0.3879,  0.5311]],\n",
       "\n",
       "        [[-1.3790,  0.1961,  0.7177,  ...,  0.4307, -0.5612,  0.3214],\n",
       "         [-0.6983, -0.6789,  0.5436,  ...,  1.2940, -0.3293,  0.8754],\n",
       "         [ 0.9518,  0.5979,  1.3345,  ...,  1.1043, -0.4029,  0.6608],\n",
       "         ...,\n",
       "         [ 0.2170,  0.5755, -0.3869,  ...,  0.6608, -0.3875,  0.5314],\n",
       "         [ 0.2170,  0.5755, -0.3869,  ...,  0.6608, -0.3875,  0.5314],\n",
       "         [ 0.2170,  0.5755, -0.3869,  ...,  0.6608, -0.6245,  0.5314]],\n",
       "\n",
       "        [[-1.3477,  0.1810,  0.7314,  ...,  0.3302, -0.6365,  0.3571],\n",
       "         [-0.6595, -0.7569,  0.5925,  ...,  1.3545, -0.3954,  0.7134],\n",
       "         [ 0.9183,  0.6637,  0.5668,  ..., -0.4739,  0.3729,  0.0509],\n",
       "         ...,\n",
       "         [ 0.2140,  0.5730, -0.3886,  ...,  0.6596, -0.3897,  0.5287],\n",
       "         [ 0.2140,  0.5730, -0.3886,  ...,  0.6596, -0.3897,  0.5287],\n",
       "         [ 0.2140,  0.5730, -0.3886,  ...,  0.1942, -0.3897,  0.5287]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c2e2f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model10.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fd61b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "27009217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdb24ebac2440228b42de1b6ebf0c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e93c590570e4adda6cab6e1591770b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08075edbc483454794bcc29d1207d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Zf5 = model5(enginput,Zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "56d67359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = EncoderStack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ccfcc16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 1 Completed\n",
      "Encoder 2 Completed\n",
      "Encoder 3 Completed\n",
      "Encoder 4 Completed\n",
      "Encoder 5 Completed\n",
      "Encoder 6 Completed\n"
     ]
    }
   ],
   "source": [
    "Zf6 = model6(deuinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "45516335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d0471ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1429, -0.1112, -0.1361,  ..., -0.1492, -0.1491, -0.1322],\n",
       "         [-0.1429, -0.1112, -0.1361,  ..., -0.1492, -0.1492, -0.1322],\n",
       "         [-0.1429, -0.1112, -0.1361,  ..., -0.1492, -0.1491, -0.1322],\n",
       "         ...,\n",
       "         [-0.1426, -0.1109, -0.1356,  ..., -0.1487, -0.1488, -0.1320],\n",
       "         [-0.1492, -0.1112, -0.1492,  ..., -0.1492, -0.1491, -0.1322],\n",
       "         [ 4.2928,  3.3573,  3.7632,  ...,  4.9766,  3.5077, -0.1492]],\n",
       "\n",
       "        [[-0.2145, -0.1938, -0.2507,  ..., -0.2507, -0.2507, -0.2189],\n",
       "         [-0.2145, -0.1938, -0.2287,  ..., -0.2507, -0.2507, -0.2189],\n",
       "         [-0.2145, -0.2507, -0.2287,  ..., -0.2507, -0.2507, -0.2189],\n",
       "         ...,\n",
       "         [-0.2145, -0.1938, -0.2287,  ..., -0.2507, -0.2507, -0.2189],\n",
       "         [-0.2502, -0.1939, -0.2282,  ..., -0.2507, -0.2500, -0.2188],\n",
       "         [-0.2145, -0.1938, -0.2287,  ..., -0.2507, -0.2507, -0.2189]],\n",
       "\n",
       "        [[-0.1250, -0.0914, -0.1152,  ..., -0.1250, -0.1230, -0.1119],\n",
       "         [-0.1250, -0.0914, -0.1152,  ..., -0.1250, -0.1230, -0.1119],\n",
       "         [ 4.3912,  3.2205,  3.6048,  ...,  4.7697,  3.3702,  3.3299],\n",
       "         ...,\n",
       "         [-0.1250, -0.1250, -0.1152,  ..., -0.1250, -0.1230, -0.1119],\n",
       "         [-0.1250, -0.0914, -0.1152,  ..., -0.1250, -0.1230, -0.1250],\n",
       "         [-0.1250, -0.0914, -0.1152,  ..., -0.1250, -0.1230, -0.1119]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1960,  0.1945,  0.1945,  ...,  0.3035,  0.1949,  0.1945],\n",
       "         [ 0.1945,  0.1945,  0.1945,  ...,  0.3035,  0.1949,  0.1945],\n",
       "         [ 0.1960,  0.1945,  0.1945,  ...,  0.3035,  0.1949,  0.1945],\n",
       "         ...,\n",
       "         [ 0.1960,  0.1945,  0.1945,  ...,  0.3035,  0.1949,  0.1945],\n",
       "         [ 0.1955,  0.1939,  0.1937,  ...,  0.3027,  0.1944,  0.1938],\n",
       "         [ 0.1960,  0.1945,  0.1945,  ...,  0.3035,  0.1949,  0.1945]],\n",
       "\n",
       "        [[-0.2241, -0.2047, -0.2413,  ..., -0.2647, -0.2647, -0.2307],\n",
       "         [-0.2241, -0.2047, -0.2413,  ..., -0.2647, -0.2647, -0.2307],\n",
       "         [-0.2241, -0.2047, -0.2413,  ..., -0.2647, -0.2647, -0.2307],\n",
       "         ...,\n",
       "         [-0.2647, -0.2047, -0.2413,  ..., -0.2647, -0.2647, -0.2307],\n",
       "         [-0.2647, -0.2047, -0.2413,  ..., -0.2647, -0.2647, -0.2307],\n",
       "         [-0.2241, -0.2047, -0.2647,  ..., -0.2647, -0.2647, -0.2307]],\n",
       "\n",
       "        [[-0.1984, -0.1756, -0.2077,  ..., -0.2278, -0.2278, -0.1992],\n",
       "         [-0.1984, -0.1756, -0.2077,  ..., -0.2278, -0.2278, -0.1992],\n",
       "         [-0.1984, -0.1756, -0.2077,  ..., -0.2278, -0.2278, -0.1992],\n",
       "         ...,\n",
       "         [-0.8638, -0.6786, -0.8862,  ..., -0.8936, -0.7970, -0.6697],\n",
       "         [-0.1984, -0.1756, -0.2077,  ..., -0.2278, -0.2278, -0.1992],\n",
       "         [-0.1984, -0.1756, -0.2278,  ..., -0.2278, -0.2278, -0.2278]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0ee93482",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = DecoderStack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "17931504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder 1 Completed\n",
      "Decoder 2 Completed\n",
      "Decoder 3 Completed\n",
      "Decoder 4 Completed\n",
      "Decoder 5 Completed\n",
      "Decoder 6 Completed\n"
     ]
    }
   ],
   "source": [
    "Zf7 = model7(enginput,Zf6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "86c4ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "12f0e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c1f96aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 1 Completed\n",
      "Encoder 2 Completed\n",
      "Encoder 3 Completed\n",
      "Encoder 4 Completed\n",
      "Encoder 5 Completed\n",
      "Encoder 6 Completed\n",
      "Decoder 1 Completed\n",
      "Decoder 2 Completed\n",
      "Decoder 3 Completed\n",
      "Decoder 4 Completed\n",
      "Decoder 5 Completed\n",
      "Decoder 6 Completed\n"
     ]
    }
   ],
   "source": [
    "Zf8 = model8(data[0],data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f9fad952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5c5834c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 512])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfdf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "14796179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = finalComponent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "56956a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zf9 = model9(Zf7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0bfcaa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zf9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748ea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d94edb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder Attention in Decoder\n",
    "class EncDecAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncDecAttention,self).__init__()\n",
    "        self.Wo = nn.Parameter(t.rand(nHEADS*HIDDEN_SIZE, d_model)).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, data, maskquery, enc_output):\n",
    "        ans = t.empty_like(enc_output)\n",
    "        enc_output = enc_output.reshape(enc_output.shape[0],nHEADS,enc_output.shape[1],-1)\n",
    "        for i,X in enumerate(data):\n",
    "            Q = maskquery[i]\n",
    "            K = enc_output[i]\n",
    "            V = enc_output[i]\n",
    "            Z = t.bmm(Q,K.transpose(1,2))/sqrt(HIDDEN_SIZE)\n",
    "            r,c = t.triu_indices(Z.shape[0],Z.shape[1],1)\n",
    "            Z[r,c] = float('-inf')            \n",
    "            Z = nn.Softmax(dim=2)(Z)\n",
    "            Z = t.einsum('ijj->ij',[Z])           \n",
    "            Z = t.einsum('ij,ijk->ijk',Z,V)\n",
    "            Z = t.reshape(Z,(Z.shape[1],-1))\n",
    "            Z = Z@self.Wo\n",
    "            Z = nn.Dropout(p=0.1)(Z)            \n",
    "            Z = nn.LayerNorm(Z.shape,device=device)(Z+X.reshape(X.shape[1],-1))\n",
    "            ans[i] = Z\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "13caaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.masked = MaskedAttention()\n",
    "        self.encdec = EncDecAttention()\n",
    "        self.feedforward = FeedForward()\n",
    "        \n",
    "    def forward(self, X, enc_output):\n",
    "        Z, Q = self.masked(X)\n",
    "        Z = self.encdec(Z, Q, enc_output)\n",
    "        Z = self.feedforward(Z)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7024f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Stack\n",
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderStack,self).__init__()\n",
    "        self.enc1 = Encoder()\n",
    "        self.enc2 = Encoder()\n",
    "        self.enc3 = Encoder()\n",
    "        self.enc4 = Encoder()\n",
    "        self.enc5 = Encoder()\n",
    "        self.enc6 = Encoder()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        Z = self.enc1(X)\n",
    "        print(\"Encoder 1 Completed\")\n",
    "        Z = self.enc2(Z)\n",
    "        print(\"Encoder 2 Completed\")\n",
    "        Z = self.enc3(Z)\n",
    "        print(\"Encoder 3 Completed\")\n",
    "        Z = self.enc4(Z)\n",
    "        print(\"Encoder 4 Completed\")\n",
    "        Z = self.enc5(Z)\n",
    "        print(\"Encoder 5 Completed\")\n",
    "        Z = self.enc6(Z)\n",
    "        print(\"Encoder 6 Completed\")\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8481c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Stack\n",
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderStack,self).__init__()\n",
    "        self.dec1 = Decoder()\n",
    "        self.dec2 = Decoder()\n",
    "        self.dec3 = Decoder()\n",
    "        self.dec4 = Decoder()\n",
    "        self.dec5 = Decoder()\n",
    "        self.dec6 = Decoder()\n",
    "        \n",
    "    def forward(self,X, enc_output):\n",
    "        Z = self.dec1(X, enc_output)\n",
    "        print(\"Decoder 1 Completed\")\n",
    "        Z = self.dec2(Z, enc_output)\n",
    "        print(\"Decoder 2 Completed\")\n",
    "        Z = self.dec3(Z, enc_output)\n",
    "        print(\"Decoder 3 Completed\")\n",
    "        Z = self.dec4(Z, enc_output)\n",
    "        print(\"Decoder 4 Completed\")\n",
    "        Z = self.dec5(Z, enc_output)\n",
    "        print(\"Decoder 5 Completed\")\n",
    "        Z = self.dec6(Z, enc_output)\n",
    "        print(\"Decoder 6 Completed\")\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cafe7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Component of Fully-Connected and Softmax Layer\n",
    "class finalComponent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(finalComponent,self).__init__()\n",
    "        self.fc = nn.Linear(d_model,len(target_vocab))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        ans = t.empty(data.shape[0],128)\n",
    "        for i,X in enumerate(data):\n",
    "            Z = self.fc(X)\n",
    "            Z = self.softmax(Z)\n",
    "            ans[i] = t.argmax(Z,dim=1)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e618ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all components into 1 class\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.deu_embed = Embeddings(512,len(source_vocab))\n",
    "        self.eng_embed = Embeddings(512,len(target_vocab))\n",
    "        self.pe = Posi\n",
    "        self.EncStack = EncoderStack()\n",
    "        self.DecStack = DecoderStack()\n",
    "        self.finalComponent = finalComponent()\n",
    "    \n",
    "    def forward(self, Xdeu, Xeng):\n",
    "        Xdeu = self.deu_embed(Xdeu)\n",
    "        Z = self.EncStack(Xdeu)\n",
    "        Xeng = self.eng_embed(Xeng)        \n",
    "        Z = self.DecStack(Xeng,Z)\n",
    "        Z = self.finalComponent(Z)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cebe848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "truemodel = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6010000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in truemodel.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cb108a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 1 Completed\n",
      "Encoder 2 Completed\n",
      "Encoder 3 Completed\n",
      "Encoder 4 Completed\n",
      "Encoder 5 Completed\n",
      "Encoder 6 Completed\n",
      "Decoder 1 Completed\n",
      "Decoder 2 Completed\n",
      "Decoder 3 Completed\n",
      "Decoder 4 Completed\n",
      "Decoder 5 Completed\n",
      "Decoder 6 Completed\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "Zfinal = truemodel(data[0],data[1])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8ca5ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.76242685317993"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e92752dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zfinal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
